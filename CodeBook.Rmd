---
title: "CodeBook.md"
author: "vstarkweather"
date: "December 20, 2014"
output:
  html_document:
    keep_md: yes
---
# Codebook.md

## Overview of the original data set
These data are based on the data sets from the UCI study "Human Activity Recognition Using Smartphones Data Set". 
The original study codebook (available at this link: http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) provides this abstract of the study (information quoted directly from the UCI document):
> Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.

## Experimental Design
The experimental design is described in the UCI document: 
> The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.

## Raw and processed data sets
Preparation of the R script, cleaning of the data, and code execution were performed on an Apple MacBook running Mac OS X version 10.7.5 operating system, usng R version 3.1.2 "Pumpkin Helmet" and RStudio version 0.98.1087.
The resulting R code "run_analysis.R" is available for downloading at this link:
http://github.com/vstarkweather/GettingCleaningDataCourseProject
To successfully execute the "run_analysis.R" script and obtain the final data set, the raw data files must reside in the R working directory of the local client machine.
Further details about the R script for cleaning the data and preparing the tidy data set are available in the README file found at http://github.com/vstarkweather/GettingCleaningDataCourseProject
On execution of the "run_analysis.R" script, a file called "HARUStudy.txt" will be written to the R working directory.

Raw data for this analysis is available at this link:
http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 
The original data set consisted of 10299 records, each comprising 561 types of measurements (or aggregated measures) from body sensors of 30 subjects for six types of activities. Note that only 66 of the measurement types are retained in the final data set resulting from the R analysis. From the UCI documentation:
> For each record in the dataset it is provided: 
>- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. 
>- Triaxial Angular velocity from the gyroscope. 
>- A 561-feature vector with time and frequency domain variables. 
>- Its activity label. 
>- An identifier of the subject who carried out the experiment.

The data set that results from executing the "run_analysis.R" script is described below.

Processed data: 
+ subject: a factor of 30 levels. Numeric identifier for each of 30 subjects in the experiment.
+ activity: a factor of six levels. Six activities were performed by each subject: LAYING, SITTING, STANDING, WALKING, WALKING UPSTAIRS, WALKING DOWNSTAIRS.
+ feature: used as a factor in this data. 66 types of measurements were recorded (values are shown below). The generic description of the features is: **domainObservationStatistic...Axis**
++ *domain* can be "time" or "frequency"
++ *Observation* is one of 66 observation types. See the full list below.
++ *Statistic* either *mean* or *std*, corresponding to an average value or its standard deviation, respectively.
++ *Axis* refers to a dimensional orientation detected by sensors in the device used to gather data. Values are X, Y, or Z.
+ measurement: a transformation (mean) of the set of mean and standard deviation values for each of the combinations of subject, activity, and feature. The values of the mean and standard deviation in the original data set were normalized to a range of -1 to 1, and thus have no units.

The complete list of the values in the variable "feature" is shown below.
 [1] "frequencyBodyAcc.mean...X"       "frequencyBodyAcc.mean...Y"      
 [3] "frequencyBodyAcc.mean...Z"       "frequencyBodyAcc.std...X"       
 [5] "frequencyBodyAcc.std...Y"        "frequencyBodyAcc.std...Z"       
 [7] "frequencyBodyAccJerk.mean...X"   "frequencyBodyAccJerk.mean...Y"  
 [9] "frequencyBodyAccJerk.mean...Z"   "frequencyBodyAccJerk.std...X"   
[11] "frequencyBodyAccJerk.std...Y"    "frequencyBodyAccJerk.std...Z"   
[13] "frequencyBodyAccJerkMag.mean.."  "frequencyBodyAccJerkMag.std.."  
[15] "frequencyBodyAccMag.mean.."      "frequencyBodyAccMag.std.."      
[17] "frequencyBodyGyro.mean...X"      "frequencyBodyGyro.mean...Y"     
[19] "frequencyBodyGyro.mean...Z"      "frequencyBodyGyro.std...X"      
[21] "frequencyBodyGyro.std...Y"       "frequencyBodyGyro.std...Z"      
[23] "frequencyBodyGyroJerkMag.mean.." "frequencyBodyGyroJerkMag.std.." 
[25] "frequencyBodyGyroMag.mean.."     "frequencyBodyGyroMag.std.."     
[27] "timeBodyAcc.mean...X"            "timeBodyAcc.mean...Y"           
[29] "timeBodyAcc.mean...Z"            "timeBodyAcc.std...X"            
[31] "timeBodyAcc.std...Y"             "timeBodyAcc.std...Z"            
[33] "timeBodyAccJerk.mean...X"        "timeBodyAccJerk.mean...Y"       
[35] "timeBodyAccJerk.mean...Z"        "timeBodyAccJerk.std...X"        
[37] "timeBodyAccJerk.std...Y"         "timeBodyAccJerk.std...Z"        
[39] "timeBodyAccJerkMag.mean.."       "timeBodyAccJerkMag.std.."       
[41] "timeBodyAccMag.mean.."           "timeBodyAccMag.std.."           
[43] "timeBodyGyro.mean...X"           "timeBodyGyro.mean...Y"          
[45] "timeBodyGyro.mean...Z"           "timeBodyGyro.std...X"           
[47] "timeBodyGyro.std...Y"            "timeBodyGyro.std...Z"           
[49] "timeBodyGyroJerk.mean...X"       "timeBodyGyroJerk.mean...Y"      
[51] "timeBodyGyroJerk.mean...Z"       "timeBodyGyroJerk.std...X"       
[53] "timeBodyGyroJerk.std...Y"        "timeBodyGyroJerk.std...Z"       
[55] "timeBodyGyroJerkMag.mean.."      "timeBodyGyroJerkMag.std.."      
[57] "timeBodyGyroMag.mean.."          "timeBodyGyroMag.std.."          
[59] "timeGravityAcc.mean...X"         "timeGravityAcc.mean...Y"        
[61] "timeGravityAcc.mean...Z"         "timeGravityAcc.std...X"         
[63] "timeGravityAcc.std...Y"          "timeGravityAcc.std...Z"         
[65] "timeGravityAccMag.mean.."        "timeGravityAccMag.std.."